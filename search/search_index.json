{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"KNN using Scikit-learn \u00b6 Pendahuluan | Algoritma kNN \u00b6 Statistical learning mengacu pada kumpulan mathematical and computation tool untuk memahami data. Dalam apa yang sering disebut supervised learning, tujuannya adalah untuk memperkirakan atau memprediksi output berdasarkan pada satu atau lebih input. Input memiliki banyak nama, seperti prediktor, variabel independen. , fitur, dan variabel yang disebut umum. Output atau output sering disebut variabel respons, atau variabel dependen. Jika responsnya kuantitatif - katakanlah, angka yang mengukur berat atau tinggi badan, kita menyebut masalah ini masalah regresi. Jika responsnya kualitatif\u2013 katakan, ya atau tidak, atau biru atau hijau, kita menyebutnya masalah klasifikasi masalah ini. Studi kasus ini berkaitan dengan satu pendekatan spesifik untuk klasifikasi. Tujuannya adalah untuk membuat classifier sehingga ketika disajikan dengan pengamatan baru yang kategorinya tidak diketahui, ia akan berusaha untuk menetapkan pengamatan itu ke kategori, atau kelas, berdasarkan pengamatan yang ia tahu kategori sebenarnya. Metode khusus ini dikenal sebagai k-Nearest Neighbors classifier, atau [kNN] (https://www.geeksforgeeks.org/k-nearest-neighbours/). Memberikan bilangan bulat positif k, katakan 5, dan titik data baru, itu pertama mengidentifikasi titik-titik k dalam data yang terdekat dengan titik dan mengklasifikasikan titik data baru sebagai milik kelas paling umum di antara mereka k tetangga. Tujuan : Bangun k kita sendiri - Klasifikasi Neighbor terdekat untuk mengklasifikasikan data dari dataset IRIS dari scikit-learn.. KNN dapat diringkas sebagai berikut : \u00b6 Menghitung jarak antara titik data baru dengan setiap contoh training. Untuk menghitung ukuran jarak seperti jarak Euclidean, jarak Hamming atau jarak Manhattan yang akan digunakan. Model memilih entri K dalam database yang paling dekat dengan titik data baru. Dan melakukan voting mayoritas yaitu kelas / label paling umum di antara entri K tersebut adalah kelas dari titik data baru. K=3, Class B will be assigned, K=6 Class A will be assigned Sumber terperinci tentang KNN tersedia disini Mengklasifikasikan Kumpulan Data IRIS \u00b6 Kita akan menguji classifier pada scikit learn dataset, yang disebut \"IRIS\" .Untuk mengimpor \"IRIS\", kita perlu mengimpor dataset dari sklearn dan memanggil fungsi dataset.\"load_iris ()\"\". Kumpulan data \"IRIS\" menyimpan informasi pada panjang sepal, lebar sepal, panjang petal & lebar petal untuk tiga kelas bunga Iris yang berbeda - Iris-Setosa, Iris-Versicolour & Iris-Verginica. Berdasarkan data dari dataset, kita perlu mengklasifikasikan dan memvisualisasikannya menggunakan classifier. Sci-kit learn (sklearn) sudah memiliki classifier pra dibangun. Kita akan membandingkan kedua classifier tersebut, [scikitlearn vs yang kami bangun] dan memeriksa / membandingkan akurasi prediksi kedua classifier tersebut. Contoh di bawah ini menunjukkan implementasi KNN pada dataset iris menggunakan perpustakaan scikit-learn. Dataset iris memiliki 50 sampel untuk setiap spesies bunga Iris yang berbeda (total 150). Untuk setiap sampel memiliki panjang sepal, lebar dan panjang kelopak dan lebar serta nama spesies (kelas / label). Bunga Iris: sepal length, sepal width, petal length, petal width 150 pengamatan 4 fitur (panjang sepal, lebar sepal, panjang petal, lebar petal) Respon variabel adalah spesies iris Klasifikasi masalah karena responsnya kategorikal. Tugas kita adalah membangun model KNN yang mengklasifikasikan spesies baru berdasarkan pengukuran sepal dan length. Kumpulan data iris tersedia di scikit-learn dan kita dapat memanfaatkannya untuk membuat KNN. Script lengkap dapat ditemukan di Git Repo Langkah 1 : Import data yang diperlukan dan periksa fitur-fiturnya. \u00b6 Import fungsi load_iris dari modul dataset scikit-learen dan buat objek Bunch iris (bunch adalah tipe objek khusus scikit-learn untuk menyimpan kumpulan data dan atributnya). Memuat dataset dan fitur iris \u00b6 # Import fungsi load_iris dan modul dataset from sklearn.datasets import load_iris # Buat banyak objek yang berisi dataset iris dan atributnya. iris = load_iris () type ( iris ) # Tampilkan data iris print ( iris . data ) output note : karena sebagai pembelajaran, saya hanya menampilkan beberapa data iris saja Setiap pengamatan mewakili satu bunga dan 4 kolom dan mewakili 4 pengukuran. Kami dapat melihat fitur (ukuran) di bawah atribut \u2018data\u2019, di mana sebagai label di bawah \u2018fitur_names\u2019. Seperti yang dapat kita lihat di bawah ini, label diberikan kode sebagai 0, 1 dan 2. Karena fitur dan break harus numerik (array Numpy) untuk model scikit-learn dan mereka harus memiliki bentuk tertentu. # Nama dari 4 fitur (nama kolom) print ( iris . feature_names ) output # Integers mewakili beberapa spesies bunga : # 0 = setosa, 1 = versicolor, 2 = virginica print ( iris . target ) output # 3 kelas target print ( iris . target_names ) print ( type ( iris . data )) print ( type ( iris . target )) output # Disini data memiliki total 150 pengamatan dan 4 fitur print ( iris . data . shape ) output # Matriks fitur dalam objek bernama X X = iris . data # Vektor respons dalam objek bernama y y = iris . target print ( X . shape ) print ( y . shape ) output Langkah 2 : Membagi data dan Melatih Model. \u00b6 Data training dan data test pada data yang sama bukanlah pendekatan yang optimal, jadi kita akan membagi data menjadi dua bagian, data training dan data test. Kita akan menggunakan fungsi \u2018train_test_split\u2019 untuk membagi data. Parameter opsional \u2018test size\u2019 menentukan persentase pemisahan. Parameter 'random_state' membuat data terpecah dengan cara yang sama setiap kali Anda menjalankan. Karena kita melatih dan menguji pada dataset yang berbeda, akurasi pengujian yang dihasilkan akan menjadi perkiraan yang lebih baik tentang seberapa baik model tersebut akan tampil pada data yang tidak terlihat. # Memecah data menjadi data training dan data tes (80:20) from sklearn.model_selection import train_test_split X_train , X_test , y_train , y_test = train_test_split ( X , y , test_size = 0.2 , random_state = 4 ) # Bentuk train dan test object print ( X_train . shape ) print ( X_test . shape ) output # bentuk objek y baru print ( y_train . shape ) print ( y_test . shape ) output Scikit-learning disusun dengan cermat ke dalam modul, sehingga kita dapat mengimport kelas yang relevan dengan mudah. Import kelas \u2018KNeighborsClassifer\u2019 dari modul \u2018neightbors\u2019 dan Instantiate estimator ('estimator\u2019 adalah istilah scikit-learning untuk sebuah model). Kita menyebut model sebagai estimator karena peran utamanya adalah memperkirakan jumlah yang tidak diketahui. Dalam contoh kami, kami membuat instance (\u2018knn\u2019) dari kelas \u2018KNeighborsClassifer\u2019, dengan kata lain kami telah membuat objek yang disebut how knn \u2019yang tahu bagaimana melakukan klasifikasi KNN setelah kami memberikan data. Parameter \u2018n_neighbors\u2019 adalah parameter tuning / parameter hiper (k). Semua parameter lain diatur ke nilai default. Metode \u2018fit\u2019 digunakan untuk melatih model tentang data pelatihan (X_train, y_train) dan metode \u2018predict\u2019 untuk melakukan pengujian pada data pengujian (X_test). Memilih nilai optimal K sangat penting, jadi kami menyesuaikan dan menguji model untuk nilai yang berbeda untuk K (dari 1 hingga 25) menggunakan loop untuk dan mencatat akurasi pengujian KNN dalam suatu variabel (skor). # import kelas KNeighborsClassifier dari sklearn from sklearn.neighbors import KNeighborsClassifier # mengimport model metrik untuk memeriksa keakuratan from sklearn import metrics # Coba jalankan dari k = 1 hingga 25 dan catat akurasi pengujian k_range = range ( 1 , 26 ) scores = {} scores_list = [] for k in k_range : knn = KNeighborsClassifier ( n_neighbors = k ) knn . fit ( X_train , y_train ) y_pred = knn . predict ( X_test ) scores [ k ] = metrics . accuracy_score ( y_test , y_pred ) scores_list . append ( metrics . accuracy_score ( y_test , y_pred )) Plot hubungan antara nilai-nilai K dan akurasi pengujian yang sesuai menggunakan perpustakaan matplotlib. Seperti yang dapat kita lihat ada peningkatan dan penurunan akurasi dan itu cukup khas ketika memeriksa kompleksitas model dengan akurasi. Secara umum sebagai nilai K meningkat tampaknya ada peningkatan dalam keakuratan dan sekali lagi jatuh. Secara umum akurasi Pelatihan meningkat seiring dengan meningkatnya kompleksitas model, untuk KNN kompleksitas model ditentukan oleh nilai K. Nilai K yang lebih besar mengarah ke batas keputusan yang lebih halus (model yang kurang kompleks). K yang lebih kecil mengarah ke model yang lebih kompleks (dapat menyebabkan overfitting). Akurasi pengujian menghukum model yang terlalu kompleks (over fitting) atau tidak cukup kompleks (underfit). Kami mendapatkan akurasi pengujian maksimum ketika model memiliki tingkat kompleksitas yang tepat, dalam kasus kami, kami dapat melihat bahwa untuk nilai K 3 hingga 19, akurasi model kami adalah 96,6%. % matplotlib inline import matplotlib.pyplot as plt # plot hubungan antara K dan akurasi pengujian plt . plot ( k_range , scores_list ) plt . xlabel ( 'Value of K for KNN' ) plt . ylabel ( 'Testing Accuracy' ) plt . show () output Untuk model akhir kami, kami dapat memilih nilai optimal K sebagai 5 (yang jatuh antara 3 dan 19) dan melatih kembali model dengan semua data yang tersedia. Dan itu akan menjadi model terakhir kami yang siap membuat prediksi. # 0 = setosa, 1 = versicolor, 2 = virginica classes = { 0 : 'setosa' , 1 : 'versicolor' , 2 : 'virginica' } # Membuat prediksi pada beberapa data yang tidak terlihat # prediksi untuk dua pengamatan acak di bawah ini x_new = [[ 3 , 4 , 5 , 2 ], [ 5 , 4 , 2 , 2 ]] y_predict = knn . predict ( x_new ) print ( classes [ y_predict [ 0 ]]) print ( classes [ y_predict [ 1 ]]) output Terimakasih telah membaca, mohon maaf jika ada salah dalam penulisan kalimat dan penjelasan yang kurang jelas. Reference : \u00b6 MachineLearning\u200a\u2014\u200aKNN using scikit-learn KNN (using scikit-learn) on Iris dataset. Scikit Learn KNN (K-Nearest Neighbors) #1","title":"KNN"},{"location":"#knn-using-scikit-learn","text":"","title":"KNN using Scikit-learn"},{"location":"#pendahuluan-algoritma-knn","text":"Statistical learning mengacu pada kumpulan mathematical and computation tool untuk memahami data. Dalam apa yang sering disebut supervised learning, tujuannya adalah untuk memperkirakan atau memprediksi output berdasarkan pada satu atau lebih input. Input memiliki banyak nama, seperti prediktor, variabel independen. , fitur, dan variabel yang disebut umum. Output atau output sering disebut variabel respons, atau variabel dependen. Jika responsnya kuantitatif - katakanlah, angka yang mengukur berat atau tinggi badan, kita menyebut masalah ini masalah regresi. Jika responsnya kualitatif\u2013 katakan, ya atau tidak, atau biru atau hijau, kita menyebutnya masalah klasifikasi masalah ini. Studi kasus ini berkaitan dengan satu pendekatan spesifik untuk klasifikasi. Tujuannya adalah untuk membuat classifier sehingga ketika disajikan dengan pengamatan baru yang kategorinya tidak diketahui, ia akan berusaha untuk menetapkan pengamatan itu ke kategori, atau kelas, berdasarkan pengamatan yang ia tahu kategori sebenarnya. Metode khusus ini dikenal sebagai k-Nearest Neighbors classifier, atau [kNN] (https://www.geeksforgeeks.org/k-nearest-neighbours/). Memberikan bilangan bulat positif k, katakan 5, dan titik data baru, itu pertama mengidentifikasi titik-titik k dalam data yang terdekat dengan titik dan mengklasifikasikan titik data baru sebagai milik kelas paling umum di antara mereka k tetangga. Tujuan : Bangun k kita sendiri - Klasifikasi Neighbor terdekat untuk mengklasifikasikan data dari dataset IRIS dari scikit-learn..","title":"Pendahuluan | Algoritma kNN"},{"location":"#knn-dapat-diringkas-sebagai-berikut","text":"Menghitung jarak antara titik data baru dengan setiap contoh training. Untuk menghitung ukuran jarak seperti jarak Euclidean, jarak Hamming atau jarak Manhattan yang akan digunakan. Model memilih entri K dalam database yang paling dekat dengan titik data baru. Dan melakukan voting mayoritas yaitu kelas / label paling umum di antara entri K tersebut adalah kelas dari titik data baru. K=3, Class B will be assigned, K=6 Class A will be assigned Sumber terperinci tentang KNN tersedia disini","title":"KNN dapat diringkas sebagai berikut :"},{"location":"#mengklasifikasikan-kumpulan-data-iris","text":"Kita akan menguji classifier pada scikit learn dataset, yang disebut \"IRIS\" .Untuk mengimpor \"IRIS\", kita perlu mengimpor dataset dari sklearn dan memanggil fungsi dataset.\"load_iris ()\"\". Kumpulan data \"IRIS\" menyimpan informasi pada panjang sepal, lebar sepal, panjang petal & lebar petal untuk tiga kelas bunga Iris yang berbeda - Iris-Setosa, Iris-Versicolour & Iris-Verginica. Berdasarkan data dari dataset, kita perlu mengklasifikasikan dan memvisualisasikannya menggunakan classifier. Sci-kit learn (sklearn) sudah memiliki classifier pra dibangun. Kita akan membandingkan kedua classifier tersebut, [scikitlearn vs yang kami bangun] dan memeriksa / membandingkan akurasi prediksi kedua classifier tersebut. Contoh di bawah ini menunjukkan implementasi KNN pada dataset iris menggunakan perpustakaan scikit-learn. Dataset iris memiliki 50 sampel untuk setiap spesies bunga Iris yang berbeda (total 150). Untuk setiap sampel memiliki panjang sepal, lebar dan panjang kelopak dan lebar serta nama spesies (kelas / label). Bunga Iris: sepal length, sepal width, petal length, petal width 150 pengamatan 4 fitur (panjang sepal, lebar sepal, panjang petal, lebar petal) Respon variabel adalah spesies iris Klasifikasi masalah karena responsnya kategorikal. Tugas kita adalah membangun model KNN yang mengklasifikasikan spesies baru berdasarkan pengukuran sepal dan length. Kumpulan data iris tersedia di scikit-learn dan kita dapat memanfaatkannya untuk membuat KNN. Script lengkap dapat ditemukan di Git Repo","title":"Mengklasifikasikan Kumpulan Data IRIS"},{"location":"#langkah-1-import-data-yang-diperlukan-dan-periksa-fitur-fiturnya","text":"Import fungsi load_iris dari modul dataset scikit-learen dan buat objek Bunch iris (bunch adalah tipe objek khusus scikit-learn untuk menyimpan kumpulan data dan atributnya).","title":"Langkah 1 : Import data yang diperlukan dan periksa fitur-fiturnya."},{"location":"#memuat-dataset-dan-fitur-iris","text":"# Import fungsi load_iris dan modul dataset from sklearn.datasets import load_iris # Buat banyak objek yang berisi dataset iris dan atributnya. iris = load_iris () type ( iris ) # Tampilkan data iris print ( iris . data ) output note : karena sebagai pembelajaran, saya hanya menampilkan beberapa data iris saja Setiap pengamatan mewakili satu bunga dan 4 kolom dan mewakili 4 pengukuran. Kami dapat melihat fitur (ukuran) di bawah atribut \u2018data\u2019, di mana sebagai label di bawah \u2018fitur_names\u2019. Seperti yang dapat kita lihat di bawah ini, label diberikan kode sebagai 0, 1 dan 2. Karena fitur dan break harus numerik (array Numpy) untuk model scikit-learn dan mereka harus memiliki bentuk tertentu. # Nama dari 4 fitur (nama kolom) print ( iris . feature_names ) output # Integers mewakili beberapa spesies bunga : # 0 = setosa, 1 = versicolor, 2 = virginica print ( iris . target ) output # 3 kelas target print ( iris . target_names ) print ( type ( iris . data )) print ( type ( iris . target )) output # Disini data memiliki total 150 pengamatan dan 4 fitur print ( iris . data . shape ) output # Matriks fitur dalam objek bernama X X = iris . data # Vektor respons dalam objek bernama y y = iris . target print ( X . shape ) print ( y . shape ) output","title":"Memuat dataset dan fitur iris"},{"location":"#langkah-2-membagi-data-dan-melatih-model","text":"Data training dan data test pada data yang sama bukanlah pendekatan yang optimal, jadi kita akan membagi data menjadi dua bagian, data training dan data test. Kita akan menggunakan fungsi \u2018train_test_split\u2019 untuk membagi data. Parameter opsional \u2018test size\u2019 menentukan persentase pemisahan. Parameter 'random_state' membuat data terpecah dengan cara yang sama setiap kali Anda menjalankan. Karena kita melatih dan menguji pada dataset yang berbeda, akurasi pengujian yang dihasilkan akan menjadi perkiraan yang lebih baik tentang seberapa baik model tersebut akan tampil pada data yang tidak terlihat. # Memecah data menjadi data training dan data tes (80:20) from sklearn.model_selection import train_test_split X_train , X_test , y_train , y_test = train_test_split ( X , y , test_size = 0.2 , random_state = 4 ) # Bentuk train dan test object print ( X_train . shape ) print ( X_test . shape ) output # bentuk objek y baru print ( y_train . shape ) print ( y_test . shape ) output Scikit-learning disusun dengan cermat ke dalam modul, sehingga kita dapat mengimport kelas yang relevan dengan mudah. Import kelas \u2018KNeighborsClassifer\u2019 dari modul \u2018neightbors\u2019 dan Instantiate estimator ('estimator\u2019 adalah istilah scikit-learning untuk sebuah model). Kita menyebut model sebagai estimator karena peran utamanya adalah memperkirakan jumlah yang tidak diketahui. Dalam contoh kami, kami membuat instance (\u2018knn\u2019) dari kelas \u2018KNeighborsClassifer\u2019, dengan kata lain kami telah membuat objek yang disebut how knn \u2019yang tahu bagaimana melakukan klasifikasi KNN setelah kami memberikan data. Parameter \u2018n_neighbors\u2019 adalah parameter tuning / parameter hiper (k). Semua parameter lain diatur ke nilai default. Metode \u2018fit\u2019 digunakan untuk melatih model tentang data pelatihan (X_train, y_train) dan metode \u2018predict\u2019 untuk melakukan pengujian pada data pengujian (X_test). Memilih nilai optimal K sangat penting, jadi kami menyesuaikan dan menguji model untuk nilai yang berbeda untuk K (dari 1 hingga 25) menggunakan loop untuk dan mencatat akurasi pengujian KNN dalam suatu variabel (skor). # import kelas KNeighborsClassifier dari sklearn from sklearn.neighbors import KNeighborsClassifier # mengimport model metrik untuk memeriksa keakuratan from sklearn import metrics # Coba jalankan dari k = 1 hingga 25 dan catat akurasi pengujian k_range = range ( 1 , 26 ) scores = {} scores_list = [] for k in k_range : knn = KNeighborsClassifier ( n_neighbors = k ) knn . fit ( X_train , y_train ) y_pred = knn . predict ( X_test ) scores [ k ] = metrics . accuracy_score ( y_test , y_pred ) scores_list . append ( metrics . accuracy_score ( y_test , y_pred )) Plot hubungan antara nilai-nilai K dan akurasi pengujian yang sesuai menggunakan perpustakaan matplotlib. Seperti yang dapat kita lihat ada peningkatan dan penurunan akurasi dan itu cukup khas ketika memeriksa kompleksitas model dengan akurasi. Secara umum sebagai nilai K meningkat tampaknya ada peningkatan dalam keakuratan dan sekali lagi jatuh. Secara umum akurasi Pelatihan meningkat seiring dengan meningkatnya kompleksitas model, untuk KNN kompleksitas model ditentukan oleh nilai K. Nilai K yang lebih besar mengarah ke batas keputusan yang lebih halus (model yang kurang kompleks). K yang lebih kecil mengarah ke model yang lebih kompleks (dapat menyebabkan overfitting). Akurasi pengujian menghukum model yang terlalu kompleks (over fitting) atau tidak cukup kompleks (underfit). Kami mendapatkan akurasi pengujian maksimum ketika model memiliki tingkat kompleksitas yang tepat, dalam kasus kami, kami dapat melihat bahwa untuk nilai K 3 hingga 19, akurasi model kami adalah 96,6%. % matplotlib inline import matplotlib.pyplot as plt # plot hubungan antara K dan akurasi pengujian plt . plot ( k_range , scores_list ) plt . xlabel ( 'Value of K for KNN' ) plt . ylabel ( 'Testing Accuracy' ) plt . show () output Untuk model akhir kami, kami dapat memilih nilai optimal K sebagai 5 (yang jatuh antara 3 dan 19) dan melatih kembali model dengan semua data yang tersedia. Dan itu akan menjadi model terakhir kami yang siap membuat prediksi. # 0 = setosa, 1 = versicolor, 2 = virginica classes = { 0 : 'setosa' , 1 : 'versicolor' , 2 : 'virginica' } # Membuat prediksi pada beberapa data yang tidak terlihat # prediksi untuk dua pengamatan acak di bawah ini x_new = [[ 3 , 4 , 5 , 2 ], [ 5 , 4 , 2 , 2 ]] y_predict = knn . predict ( x_new ) print ( classes [ y_predict [ 0 ]]) print ( classes [ y_predict [ 1 ]]) output Terimakasih telah membaca, mohon maaf jika ada salah dalam penulisan kalimat dan penjelasan yang kurang jelas.","title":"Langkah 2 : Membagi data dan Melatih Model."},{"location":"#reference","text":"MachineLearning\u200a\u2014\u200aKNN using scikit-learn KNN (using scikit-learn) on Iris dataset. Scikit Learn KNN (K-Nearest Neighbors) #1","title":"Reference :"},{"location":"license/","text":"License \u00b6 MIT License Copyright \u00a9 2016 - 2019 Martin Donath Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"license/#license","text":"MIT License Copyright \u00a9 2016 - 2019 Martin Donath Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"tree/","text":"Klasifikas Decision Tree menggunakan bahasa R \u00b6 Classification Tree \u00b6 Pohon keputusan adalah alat pendukung keputusan yang menggunakan model keputusan seperti pohon dan kemungkinan konsekuensinya, termasuk hasil acara kebetulan, biaya sumber daya, dan utilitas. Ini adalah salah satu cara untuk menampilkan algoritma yang hanya berisi pernyataan kontrol bersyarat. \u200b Pohon keputusan biasanya digunakan dalam riset operasi, khususnya dalam analisis keputusan, untuk membantu mengidentifikasi strategi yang paling mungkin untuk mencapai tujuan, tetapi juga merupakan alat yang populer dalam pembelajaran mesin. \u200b Pohon keputusan adalah struktur seperti bagan alur di mana setiap simpul internal mewakili \"tes\" pada atribut (misalnya apakah koin balik muncul kepala atau ekor), masing-masing cabang mewakili hasil pengujian, dan setiap simpul daun mewakili label kelas (keputusan diambil setelah menghitung semua atribut). Jalur dari root ke leaf mewakili aturan klasifikasi. \u200b Dalam analisis keputusan, pohon keputusan dan diagram pengaruh yang terkait erat digunakan sebagai alat pendukung keputusan visual dan analitis, di mana nilai yang diharapkan (atau utilitas yang diharapkan) dari alternatif yang bersaing dihitung. \u200b ### Pohon keputusan terdiri dari tiga jenis simpul: 1. Node keputusan - biasanya diwakili oleh kuadrat 2. Peluang node - biasanya diwakili oleh lingkaran 3. Node akhir - biasanya diwakili oleh segitiga [![Material for MkDocs](assets/images/20.png)](assets/images/material.png) Pohon keputusan biasanya digunakan dalam riset operasi dan manajemen operasi. Jika, dalam praktiknya, keputusan harus diambil secara online tanpa penarikan kembali di bawah pengetahuan yang tidak lengkap, pohon keputusan harus diparalelkan dengan model probabilitas sebagai model pilihan terbaik atau algoritma model seleksi online. Penggunaan lain dari pohon keputusan adalah sebagai alat deskriptif untuk menghitung probabilitas bersyarat. \u200b Pohon keputusan, diagram pengaruh, fungsi utilitas, dan alat dan metode analisis keputusan lainnya diajarkan kepada siswa sarjana di sekolah bisnis, ekonomi kesehatan, dan kesehatan masyarakat, dan merupakan contoh penelitian operasi atau metode ilmu manajemen. \u200b Baik langsung saja, pertama kalian harus install dulu packages \"data.tree\", tentunya selanjutnya jalankan. Kita coba menggunakan data yang sudah ada di R yaitu mushroom. \u200b install.packages ( \"data.tree\" ) library ( data.tree ) [![Material for MkDocs](assets/images/15.png)](assets/images/material.png) berikut saya bagikan script yang ada di ran R: Pertama dibuat dulu nih beberapa fungsi, yang ini untuk mengambil panjang data yang telah unik. IsPure <- function ( data ) { length ( unique ( data[ , ncol ( data ) ] )) == 1 } Entropi** adalah ukuran kemurnian dataset. Rumusnya kayak gini (please jangan tanyakan rumusnya dari mana, hehe) Entropy <- function ( vls ) { res <- vls / sum ( vls ) * log2 ( vls / sum ( vls )) res[vls == 0 ] <- 0 - sum ( res ) } Secara matematis, **Gain Informasi** IG didefinisikan sebagai: [![Material for MkDocs](assets/images/19.png)](assets/images/material.png) Dengan kata lain, Gain Informasi mengukur perbedaan antara entropi sebelum perpecahan, dan jumlah bobot entropi setelah perpecahan. Bingung? Sama hehe mari kita tulis langsung dalam bahasa R: InformationGain <- function ( tble ) { entropyBefore <- Entropy ( colSums ( tble )) s <- rowSums ( tble ) entropyAfter <- sum ( s / sum ( s ) * apply ( tble , MARGIN = 1 , FUN = Entropy )) informationGain <- entropyBefore - entropyAfter return ( informationGain )} Setelah fungsi-fungsi pendukung siap. selanjutnya kita buat fungsi untuk prediksinya. TrainID3 <- function ( node , data ) { node $ obsCount <- nrow ( data ) #if the data-set is pure (e.g. all toxic), then if ( IsPure ( data )) { #construct a leaf having the name of the pure feature (e.g. 'toxic') child <- node $ AddChild ( unique ( data[ , ncol ( data ) ] )) node $ feature <- tail ( names ( data ), 1 ) child $ obsCount <- nrow ( data ) child $ feature <- '' } else { #calculate the information gain ig <- sapply ( colnames ( data ) [ - ncol ( data ) ] , function ( x ) InformationGain ( table ( data[ , x] , data[ , ncol ( data ) ] ) ) ) #chose the feature with the highest information gain (e.g. 'color') #if more than one feature have the same information gain, then take #the first one feature <- names ( which.max ( ig )) node $ feature <- feature #take the subset of the data-set having that feature value childObs <- split ( data[ , names ( data ) != feature , drop = FALSE ] , data[ , feature] , drop = TRUE ) for ( i in 1 : length ( childObs )) { #construct a child having the name of that feature value (e.g. 'red') child <- node $ AddChild ( names ( childObs ) [i] ) #call the algorithm recursively on the child and the subset TrainID3 ( child , childObs[[i]] ) } } } Saatnya kita melakukan training menggunakan data mushroom yang ada di packages data.tree. library ( data.tree ) data ( mushroom ) mushroom [![Material for MkDocs](assets/images/16.png)](assets/images/material.png) tree <- Node $ new ( \"mushroom\" ) TrainID3 ( tree , mushroom ) print ( tree , \"feature\" , \"obsCount\" ) Nah. hasil tree yang kita dapatkan seperti berikut. [![Material for MkDocs](assets/images/17.png)](assets/images/material.png) Tentu setelah mendapatkan model, kalian tidak berhenti disitu dong. Kasian modelnya tidak digunakan untuk prediksi. Oke selanjutnya kita akan menggunakan model tersebut untuk melakukan prediksi. Terlebih dahulu kita buat fungsinya. Predict <- function ( tree , features ) { if ( tree $ children[[1]] $ isLeaf ) return ( tree $ children[[1]] $ name ) child <- tree $ children[[features[[tree $ feature]]]] return ( Predict ( child , features )) } Model sudah tersedia, fungsi untuk melakukan prediksi sudah ada. Selanjutnya kita butuh data apa yang mau diprediksi. nah misalnya kita mau prediksi jika warnanya merah, lalu ukurannya besar, dan memiliki points Predict ( tree , c ( color = 'red' , size = 'large' , points = 'yes' ) ) Hasil prediksinya adalah [![Material for MkDocs](assets/images/18.png)](assets/images/material.png) Sebetulnya ada jalan yang lebih pendek, daripada kalian harus membuat fungsi tersebut. Itu hanya buat pembelajaran agar kita bisa lebih memahami flow dari analisis ini yang diberikan oleh Cran R. Terimakasih telah membaca, mohon maaf jika ada salah dalam penulisan kalimat dan penjelasan yang kurang jelas. ##### Reference : [Decission Tree ](https://en.wikipedia.org/wiki/Decision_tree) [Klasifikasi Menggunakan Decision Tree di R ](http://www.masterstatistik.com/2017/10/klasifikasi-menggunakan-decision-tree.html)","title":"Decision Tree"},{"location":"tree/#klasifikas-decision-tree-menggunakan-bahasa-r","text":"","title":"Klasifikas Decision Tree menggunakan bahasa R"},{"location":"tree/#classification-tree","text":"Pohon keputusan adalah alat pendukung keputusan yang menggunakan model keputusan seperti pohon dan kemungkinan konsekuensinya, termasuk hasil acara kebetulan, biaya sumber daya, dan utilitas. Ini adalah salah satu cara untuk menampilkan algoritma yang hanya berisi pernyataan kontrol bersyarat. \u200b Pohon keputusan biasanya digunakan dalam riset operasi, khususnya dalam analisis keputusan, untuk membantu mengidentifikasi strategi yang paling mungkin untuk mencapai tujuan, tetapi juga merupakan alat yang populer dalam pembelajaran mesin. \u200b Pohon keputusan adalah struktur seperti bagan alur di mana setiap simpul internal mewakili \"tes\" pada atribut (misalnya apakah koin balik muncul kepala atau ekor), masing-masing cabang mewakili hasil pengujian, dan setiap simpul daun mewakili label kelas (keputusan diambil setelah menghitung semua atribut). Jalur dari root ke leaf mewakili aturan klasifikasi. \u200b Dalam analisis keputusan, pohon keputusan dan diagram pengaruh yang terkait erat digunakan sebagai alat pendukung keputusan visual dan analitis, di mana nilai yang diharapkan (atau utilitas yang diharapkan) dari alternatif yang bersaing dihitung. \u200b ### Pohon keputusan terdiri dari tiga jenis simpul: 1. Node keputusan - biasanya diwakili oleh kuadrat 2. Peluang node - biasanya diwakili oleh lingkaran 3. Node akhir - biasanya diwakili oleh segitiga [![Material for MkDocs](assets/images/20.png)](assets/images/material.png) Pohon keputusan biasanya digunakan dalam riset operasi dan manajemen operasi. Jika, dalam praktiknya, keputusan harus diambil secara online tanpa penarikan kembali di bawah pengetahuan yang tidak lengkap, pohon keputusan harus diparalelkan dengan model probabilitas sebagai model pilihan terbaik atau algoritma model seleksi online. Penggunaan lain dari pohon keputusan adalah sebagai alat deskriptif untuk menghitung probabilitas bersyarat. \u200b Pohon keputusan, diagram pengaruh, fungsi utilitas, dan alat dan metode analisis keputusan lainnya diajarkan kepada siswa sarjana di sekolah bisnis, ekonomi kesehatan, dan kesehatan masyarakat, dan merupakan contoh penelitian operasi atau metode ilmu manajemen. \u200b Baik langsung saja, pertama kalian harus install dulu packages \"data.tree\", tentunya selanjutnya jalankan. Kita coba menggunakan data yang sudah ada di R yaitu mushroom. \u200b install.packages ( \"data.tree\" ) library ( data.tree ) [![Material for MkDocs](assets/images/15.png)](assets/images/material.png) berikut saya bagikan script yang ada di ran R: Pertama dibuat dulu nih beberapa fungsi, yang ini untuk mengambil panjang data yang telah unik. IsPure <- function ( data ) { length ( unique ( data[ , ncol ( data ) ] )) == 1 } Entropi** adalah ukuran kemurnian dataset. Rumusnya kayak gini (please jangan tanyakan rumusnya dari mana, hehe) Entropy <- function ( vls ) { res <- vls / sum ( vls ) * log2 ( vls / sum ( vls )) res[vls == 0 ] <- 0 - sum ( res ) } Secara matematis, **Gain Informasi** IG didefinisikan sebagai: [![Material for MkDocs](assets/images/19.png)](assets/images/material.png) Dengan kata lain, Gain Informasi mengukur perbedaan antara entropi sebelum perpecahan, dan jumlah bobot entropi setelah perpecahan. Bingung? Sama hehe mari kita tulis langsung dalam bahasa R: InformationGain <- function ( tble ) { entropyBefore <- Entropy ( colSums ( tble )) s <- rowSums ( tble ) entropyAfter <- sum ( s / sum ( s ) * apply ( tble , MARGIN = 1 , FUN = Entropy )) informationGain <- entropyBefore - entropyAfter return ( informationGain )} Setelah fungsi-fungsi pendukung siap. selanjutnya kita buat fungsi untuk prediksinya. TrainID3 <- function ( node , data ) { node $ obsCount <- nrow ( data ) #if the data-set is pure (e.g. all toxic), then if ( IsPure ( data )) { #construct a leaf having the name of the pure feature (e.g. 'toxic') child <- node $ AddChild ( unique ( data[ , ncol ( data ) ] )) node $ feature <- tail ( names ( data ), 1 ) child $ obsCount <- nrow ( data ) child $ feature <- '' } else { #calculate the information gain ig <- sapply ( colnames ( data ) [ - ncol ( data ) ] , function ( x ) InformationGain ( table ( data[ , x] , data[ , ncol ( data ) ] ) ) ) #chose the feature with the highest information gain (e.g. 'color') #if more than one feature have the same information gain, then take #the first one feature <- names ( which.max ( ig )) node $ feature <- feature #take the subset of the data-set having that feature value childObs <- split ( data[ , names ( data ) != feature , drop = FALSE ] , data[ , feature] , drop = TRUE ) for ( i in 1 : length ( childObs )) { #construct a child having the name of that feature value (e.g. 'red') child <- node $ AddChild ( names ( childObs ) [i] ) #call the algorithm recursively on the child and the subset TrainID3 ( child , childObs[[i]] ) } } } Saatnya kita melakukan training menggunakan data mushroom yang ada di packages data.tree. library ( data.tree ) data ( mushroom ) mushroom [![Material for MkDocs](assets/images/16.png)](assets/images/material.png) tree <- Node $ new ( \"mushroom\" ) TrainID3 ( tree , mushroom ) print ( tree , \"feature\" , \"obsCount\" ) Nah. hasil tree yang kita dapatkan seperti berikut. [![Material for MkDocs](assets/images/17.png)](assets/images/material.png) Tentu setelah mendapatkan model, kalian tidak berhenti disitu dong. Kasian modelnya tidak digunakan untuk prediksi. Oke selanjutnya kita akan menggunakan model tersebut untuk melakukan prediksi. Terlebih dahulu kita buat fungsinya. Predict <- function ( tree , features ) { if ( tree $ children[[1]] $ isLeaf ) return ( tree $ children[[1]] $ name ) child <- tree $ children[[features[[tree $ feature]]]] return ( Predict ( child , features )) } Model sudah tersedia, fungsi untuk melakukan prediksi sudah ada. Selanjutnya kita butuh data apa yang mau diprediksi. nah misalnya kita mau prediksi jika warnanya merah, lalu ukurannya besar, dan memiliki points Predict ( tree , c ( color = 'red' , size = 'large' , points = 'yes' ) ) Hasil prediksinya adalah [![Material for MkDocs](assets/images/18.png)](assets/images/material.png) Sebetulnya ada jalan yang lebih pendek, daripada kalian harus membuat fungsi tersebut. Itu hanya buat pembelajaran agar kita bisa lebih memahami flow dari analisis ini yang diberikan oleh Cran R. Terimakasih telah membaca, mohon maaf jika ada salah dalam penulisan kalimat dan penjelasan yang kurang jelas. ##### Reference : [Decission Tree ](https://en.wikipedia.org/wiki/Decision_tree) [Klasifikasi Menggunakan Decision Tree di R ](http://www.masterstatistik.com/2017/10/klasifikasi-menggunakan-decision-tree.html)","title":"Classification Tree"}]}